{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCY6UbkkI9_N"
      },
      "source": [
        "# Style Transfer\n",
        "\n",
        "<img src=\"https://i0.wp.com/chelseatroy.com/wp-content/uploads/2018/12/neural_style_transfer.png?resize=768%2C311&ssl=1\">\n",
        "\n",
        "La idea de este trabajo final es reproducir el siguiente paper:\n",
        "\n",
        "https://arxiv.org/pdf/1508.06576.pdf\n",
        "\n",
        "El objetivo es transferir el estilo de una imagen dada a otra imagen distinta. \n",
        "\n",
        "Como hemos visto en clase, las primeras capas de una red convolucional se activan ante la presencia de ciertos patrones vinculados a detalles muy pequeños.\n",
        "\n",
        "A medida que avanzamos en las distintas capas de una red neuronal convolucional, los filtros se van activando a medida que detectan patrones de formas cada vez mas complejos.\n",
        "\n",
        "Lo que propone este paper es asignarle a la activación de las primeras capas de una red neuronal convolucional (por ejemplo VGG19) la definición del estilo y a la activación de las últimas capas de la red neuronal convolucional, la definición del contenido.\n",
        "\n",
        "La idea de este paper es, a partir de dos imágenes (una que aporte el estilo y otra que aporte el contenido) analizar cómo es la activación de las primeras capas para la imagen que aporta el estilo y cómo es la activación de las últimas capas de la red convolucional para la imagen que aporta el contenido. A partir de esto se intentará sintetizar una imagen que active los filtros de las primeras capas que se activaron con la imagen que aporta el estilo y los filtros de las últimas capas que se activaron con la imagen que aporta el contenido.\n",
        "\n",
        "A este procedimiento se lo denomina neural style transfer.\n",
        "\n",
        "# En este trabajo se deberá leer el paper mencionado y en base a ello, entender la implementación que se muestra a continuación y contestar preguntas sobre la misma.\n",
        "\n",
        "# Una metodología posible es hacer una lectura rápida del paper (aunque esto signifique no entender algunos detalles del mismo) y luego ir analizando el código y respondiendo las preguntas. A medida que se planteen las preguntas, volviendo a leer secciones específicas del paper terminará de entender los detalles que pudieran haber quedado pendientes.\n",
        "\n",
        "Lo primero que haremos es cargar dos imágenes, una que aporte el estilo y otra que aporte el contenido. A tal fin utilizaremos imágenes disponibles en la web."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "kyHsa2t0SxZi",
        "outputId": "e72fcf52-62ed-42f1-f64e-cdb05d049797"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\"wget\" no se reconoce como un comando interno o externo,\n",
            "programa o archivo por lotes ejecutable.\n",
            "\"wget\" no se reconoce como un comando interno o externo,\n",
            "programa o archivo por lotes ejecutable.\n",
            "La sintaxis del comando no es correcta.\n"
          ]
        }
      ],
      "source": [
        "# Imagen para estilo\n",
        "!wget https://www.savinarte.com/wp-content/uploads/2018/11/Kandinsky_001.jpg\n",
        "\n",
        "# Imagen para contenido\n",
        "!wget https://upload.wikimedia.org/wikipedia/commons/0/04/Labrador_Retriever_%281210559%29.jpg\n",
        "\n",
        "# Creamos el directorio para los archivos de salida\n",
        "!mkdir /content/output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow._api.v2.compat.v1 as tf\n",
        "tf.compat.v1.disable_eager_execution()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "id": "NIxH20o2eFoc",
        "outputId": "4785bcbb-4070-4e68-c2b5-4a1dfdccbad2"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, save_img, img_to_array\n",
        "import numpy as np\n",
        "from scipy.optimize import fmin_l_bfgs_b\n",
        "import time\n",
        "import argparse\n",
        "\n",
        "from tensorflow.keras.applications import vgg19\n",
        "from tensorflow.keras import backend as K\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iLkV1bnFl_tK"
      },
      "outputs": [],
      "source": [
        "# Definimos las imagenes que vamos a utilizar, y el directorio de salida\n",
        "\n",
        "base_image_path = Path(\"/content/Labrador_Retriever_(1210559).jpg\")\n",
        "style_reference_image_path = Path(\"/content/Kandinsky_001.jpg\")\n",
        "result_prefix = Path(\"/content/output\")\n",
        "iterations = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz2PeGfpeYzj"
      },
      "source": [
        "# 1) En base a lo visto en el paper ¿Qué significan los parámetros definidos en la siguiente celda?\n",
        "\n",
        "Respuesta: \n",
        "\n",
        "Los parametros \"total_variation_weight\" (Peso asociado con la pérdida de variación total), \"style_weight\" (Peso asignado a la perdida del estilo) y  \"content_weight\" (Peso asociado a la pérdida de contenido) son pesos que se usan para equilibrar los diferentes componentes de la función de pérdida total en el proceso de la estilización basada en el metodo descripto. Estos pesos determinan la importancia relativa de cada término en la función de pérdida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "P9Dt3aaEmJWS"
      },
      "outputs": [],
      "source": [
        "total_variation_weight = 0.1\n",
        "style_weight = 10\n",
        "content_weight = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CQQJOhCVuse6"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "Could not import PIL.Image. The use of `load_img` requires PIL.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25588\\995548232.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Definimos el tamaño de las imágenes a utilizar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_image_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mimg_nrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m400\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimg_ncols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mimg_nrows\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\diego\\anaconda3\\envs\\yolo\\lib\\site-packages\\keras\\utils\\image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    413\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpil_image\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m         raise ImportError(\n\u001b[1;32m--> 415\u001b[1;33m             \u001b[1;34m\"Could not import PIL.Image. The use of `load_img` requires PIL.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m         )\n\u001b[0;32m    417\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mImportError\u001b[0m: Could not import PIL.Image. The use of `load_img` requires PIL."
          ]
        }
      ],
      "source": [
        "# Definimos el tamaño de las imágenes a utilizar\n",
        "width, height = load_img(base_image_path).size\n",
        "img_nrows = 400\n",
        "img_ncols = int(width * img_nrows / height)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg2ct-8agm1E"
      },
      "source": [
        "# 2) Explicar qué hace la siguiente celda. En especial las últimas dos líneas de la función antes del return. ¿Por qué?\n",
        "\n",
        "Ayuda: https://keras.io/applications/\n",
        "\n",
        "Respuesta: La función preprocess_image esta diseñada para cargar y preprocesar una imagen para que pueda ser utilizada por la red VGG19. Las ultimas dos lineas antes del return son criticas para garantizar que la imagen esté en el formato correcto para ser pasada a la red VGG19. La primera asegura que la imagen se presente en un ormato de batch, y la segunda realiza el preprocesamiento especifico requerido por la VGG19."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAkljg4zuzYd"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(image_path):\n",
        "    img = load_img(image_path, target_size=(img_nrows, img_ncols))\n",
        "    img = img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = vgg19.preprocess_input(img)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTf0YDSagt10"
      },
      "source": [
        "# 3) Habiendo comprendido lo que hace la celda anterior, explique de manera muy concisa qué hace la siguiente celda. ¿Qué relación tiene con la celda anterior?\n",
        "\n",
        "Respuesta: La función deprocess_image realiza la operación inversa a la función anterior, ya que preprocess_image prepara una imagen para ser procesada por la red VGG19, deprocess_image transforma la imagen procesada por la red a un formato visualizable y comprensible. En resumen, redimensiona la imagen a su tamaño original, quita la media que fue aplicada durante el preprocesamiento, convierte la imagen de BGR a RGB y se asegura que los pixeles esten en el rango [0,255] y los convierte en enteros. Por lo tanto la relación que tienen ambas celdas es que, despues de procesar la imagen con VGG19, se usara la función deprocess para convertir la salida de la red nuevamente en una imagen visualizable en su formato original."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5LaTrsAu14z"
      },
      "outputs": [],
      "source": [
        "def deprocess_image(x):\n",
        "    x = x.reshape((img_nrows, img_ncols, 3))\n",
        "    # Remove zero-center by mean pixel\n",
        "    x[:, :, 0] += 103.939\n",
        "    x[:, :, 1] += 116.779\n",
        "    x[:, :, 2] += 123.68\n",
        "    # 'BGR'->'RGB'\n",
        "    x = x[:, :, ::-1]\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYNio09mu4S3"
      },
      "outputs": [],
      "source": [
        "# get tensor representations of our images\n",
        "# K.variable convierte un numpy array en un tensor, para \n",
        "base_image = K.variable(preprocess_image(base_image_path))\n",
        "style_reference_image = K.variable(preprocess_image(style_reference_image_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "a1Lbw02Uu--o",
        "outputId": "6cc926fa-55af-43fa-fe91-3b68c0910502"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "combination_image = K.placeholder((1, img_nrows, img_ncols, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJEi0YI3Uzrm"
      },
      "source": [
        "Aclaración:\n",
        "\n",
        "La siguiente celda sirve para procesar las tres imagenes (contenido, estilo y salida) en un solo batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGO_jGFfvEbF"
      },
      "outputs": [],
      "source": [
        "# combine the 3 images into a single Keras tensor\n",
        "input_tensor = K.concatenate([base_image,\n",
        "                              style_reference_image,\n",
        "                              combination_image], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "tdG59VRavHGB",
        "outputId": "a133befb-68d1-4c51-99e6-417c1103f726"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 3s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "Model loaded.\n"
          ]
        }
      ],
      "source": [
        "# build the VGG19 network with our 3 images as input\n",
        "# the model will be loaded with pre-trained ImageNet weights\n",
        "model = vgg19.VGG19(input_tensor=input_tensor,\n",
        "                    weights='imagenet', include_top=False)\n",
        "print('Model loaded.')\n",
        "\n",
        "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
        "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70-vs_jZkKVc"
      },
      "source": [
        "# 4) En la siguientes celdas:\n",
        "\n",
        "- ¿Qué es la matriz de Gram?¿Para qué se usa? \n",
        "\n",
        "La matriz de Gram es un recurso matematico que captura la correlación entre los canales de una caracteristica en redes neuronales convolucionales. En el contexto del paper, la matriz se utiliza para representar el estilo de una imagen es decir, las pautas de respuesta conjunta de los mapas de características de la capa.\n",
        "\n",
        "- ¿Por qué se permutan las dimensiones de x?\n",
        "\n",
        " Se permuta las dimensiones de X para preparar el tensor de manera que pueda ser compactado adecuadamente y, posteriormente, utilizado para calcular la matriz de Gram. El objetivo es transformar el tensor original en una forma donde los canales estén en las filas y las características de espacio (altura * ancho) estén en las columnas, haciendo posible el cálculo de las correlaciones entre canales con un producto punto simple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1FODPATvJ1k"
      },
      "outputs": [],
      "source": [
        "def gram_matrix(x):\n",
        "    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
        "    gram = K.dot(features, K.transpose(features))\n",
        "    return gram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBQkKFY0Rbx-"
      },
      "source": [
        "# 5) Losses:\n",
        "\n",
        "Explicar qué mide cada una de las losses en las siguientes tres celdas.\n",
        "\n",
        "Rta:\n",
        "\n",
        "1- La función style_loss mide cuánto difiere el estilo de una imagen generada (combinación) de una imagen de estilo de referencia. La \"diferencia de estilo\" se cuantifica a través de las diferencias entre las matrices de Gram de las dos imágenes, que capturan las correlaciones entre los canales de características en una capa específica de una CNN.\n",
        "\n",
        "2- La función content_loss mide cuánto difiere el contenido de una imagen generada (combinación) de una imagen base de referencia. Esta \"diferencia de contenido\" se cuantifica mediante la distancia cuadrada entre las características de las dos imágenes. En el contexto de la transferencia de estilo, la \"imagen base\" es la imagen original a la que queremos aplicar el estilo, y esta función ayuda a garantizar que la imagen resultante aún retenga el contenido de la imagen original mientras se le aplica un nuevo estilo.\n",
        "\n",
        "3- La función total_variation_loss mide la variación o la discontinuidad en la imagen, tanto vertical como horizontalmente. Esta pérdida se utiliza para promover la suavidad y coherencia en la imagen generada, reduciendo así el ruido y los artefactos. Es especialmente útil en la transferencia de estilo para garantizar que la imagen resultante sea visualmente agradable y no contenga visuales no deseados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-Gt0ahWvN6q"
      },
      "outputs": [],
      "source": [
        "def style_loss(style, combination):\n",
        "    assert K.ndim(style) == 3\n",
        "    assert K.ndim(combination) == 3\n",
        "    S = gram_matrix(style)\n",
        "    C = gram_matrix(combination)\n",
        "    channels = 3\n",
        "    size = img_nrows * img_ncols\n",
        "    return K.sum(K.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCqnju5RvQCo"
      },
      "outputs": [],
      "source": [
        "def content_loss(base, combination):\n",
        "    return K.sum(K.square(combination - base))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udEp5h31vRnY"
      },
      "outputs": [],
      "source": [
        "def total_variation_loss(x):\n",
        "    assert K.ndim(x) == 4\n",
        "    a = K.square(\n",
        "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n",
        "    b = K.square(\n",
        "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n",
        "    return K.sum(K.pow(a + b, 1.25))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-65vcinbvTZ0"
      },
      "outputs": [],
      "source": [
        "# Armamos la loss total\n",
        "loss = K.variable(0.0)\n",
        "layer_features = outputs_dict['block5_conv2']\n",
        "base_image_features = layer_features[0, :, :, :]\n",
        "combination_features = layer_features[2, :, :, :]\n",
        "loss = loss + content_weight * content_loss(base_image_features,\n",
        "                                            combination_features)\n",
        "\n",
        "feature_layers = ['block1_conv1', 'block2_conv1',\n",
        "                  'block3_conv1', 'block4_conv1',\n",
        "                  'block5_conv1']\n",
        "for layer_name in feature_layers:\n",
        "    layer_features = outputs_dict[layer_name]\n",
        "    style_reference_features = layer_features[1, :, :, :] \n",
        "    combination_features = layer_features[2, :, :, :]\n",
        "    sl = style_loss(style_reference_features, combination_features)\n",
        "    loss = loss + (style_weight / len(feature_layers)) * sl\n",
        "loss = loss + total_variation_weight * total_variation_loss(combination_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "pbz4n1OhvV2K",
        "outputId": "c2b208c6-7ddd-4a40-eeda-525f0809b963"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        }
      ],
      "source": [
        "grads = K.gradients(loss, combination_image)\n",
        "\n",
        "outputs = [loss]\n",
        "if isinstance(grads, (list, tuple)):\n",
        "    outputs += grads\n",
        "else:\n",
        "    outputs.append(grads)\n",
        "\n",
        "f_outputs = K.function([combination_image], outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JbydbOaVcvU"
      },
      "source": [
        "# 6) Explique el propósito de las siguientes tres celdas. ¿Qué hace la función fmin_l_bfgs_b? ¿En qué se diferencia con la implementación del paper? ¿Se puede utilizar alguna alternativa?\n",
        "\n",
        "Respuesta: \n",
        "\n",
        "Las tres celdas presentadas están diseñadas para interactuar con la función de optimización fmin_l_bfgs_b de SciPy. Esta función optimiza una función objetivo dada, en este caso, la función de pérdida compuesta que combina la pérdida de contenido, la pérdida de estilo y la pérdida de variación total.\n",
        "\n",
        "Función eval_loss_and_grads:\n",
        "\n",
        "Ajusta la forma del tensor x a la dimensión esperada.\n",
        "Usa f_outputs([x]) para obtener la pérdida y los gradientes. En este caso, f_outputs hace referencia a una función Keras que devuelve tanto el valor de la pérdida como sus gradientes cuando se le da una imagen, en resumen la función devuelve la pérdida y sus gradientes en un formato adecuado para el optimizador.\n",
        "\n",
        "Clase Evaluator:\n",
        "\n",
        "Esta clase está diseñada para mejorar el optimizador fmin_l_bfgs_b: necesita llamar a las funciones de pérdida y gradientes por separado, pero calcular estas dos cosas por separado en el contexto de las redes neuronales es ineficiente. La solución es calcular ambos al mismo tiempo y almacenarlos para su uso posterior.\n",
        "loss y grads son dos métodos que serán llamados por el optimizador.\n",
        "loss calcula y almacena tanto el valor de pérdida como los gradientes.\n",
        "grads simplemente devuelve los gradientes previamente calculados.\n",
        "\n",
        "Función fmin_l_bfgs_b:\n",
        "\n",
        "Es una función de optimización en el módulo scipy.optimize que realiza la optimización utilizando el algoritmo L-BFGS-B (Limited-memory Broyden-Fletcher-Goldfarb-Shanno with Box constraints). Esta optimización es adecuada para problemas con un gran número de variables y se utiliza aca porque puede manejar eficientemente la optimización de los píxeles de la imagen.\n",
        "\n",
        "Diferencia con la implementación del paper:\n",
        "\n",
        "En el paper original, los autores emplearon una técnica de descenso de gradiente para minimizar la función de pérdida. En la implementación que presente, se usa el algoritmo L-BFGS-B, que es una variante mas avanzada del método de descenso de gradiente.\n",
        "\n",
        "Alternativas:\n",
        "\n",
        "Se pueden utilizar otros algoritmos de optimización, como Adam o RMSprop. Sin embargo, en la práctica, fmin_l_bfgs_b puede ser mas efectivo para este tipo de tarea. El uso de L-BFGS-B en lugar de un optimizador tradicional como Adam tiende a producir imágenes con menos ruido y más coherentes visualmente en menos iteraciones.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVE1_qemvZeN"
      },
      "outputs": [],
      "source": [
        "def eval_loss_and_grads(x):\n",
        "    x = x.reshape((1, img_nrows, img_ncols, 3))\n",
        "    outs = f_outputs([x])\n",
        "    loss_value = outs[0]\n",
        "    if len(outs[1:]) == 1:\n",
        "        grad_values = outs[1].flatten().astype('float64')\n",
        "    else:\n",
        "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
        "    return loss_value, grad_values\n",
        "\n",
        "# this Evaluator class makes it possible\n",
        "# to compute loss and gradients in one pass\n",
        "# while retrieving them via two separate functions,\n",
        "# \"loss\" and \"grads\". This is done because scipy.optimize\n",
        "# requires separate functions for loss and gradients,\n",
        "# but computing them separately would be inefficient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qbl9roIgvdb1"
      },
      "outputs": [],
      "source": [
        "class Evaluator(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.loss_value = None\n",
        "        self.grads_values = None\n",
        "\n",
        "    def loss(self, x):\n",
        "        assert self.loss_value is None\n",
        "        loss_value, grad_values = eval_loss_and_grads(x)\n",
        "        self.loss_value = loss_value\n",
        "        self.grad_values = grad_values\n",
        "        return self.loss_value\n",
        "\n",
        "    def grads(self, x):\n",
        "        assert self.loss_value is not None\n",
        "        grad_values = np.copy(self.grad_values)\n",
        "        self.loss_value = None\n",
        "        self.grad_values = None\n",
        "        return grad_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb0yOEl-WOE6"
      },
      "source": [
        "# 7) Ejecute la siguiente celda y observe las imágenes de salida en cada iteración."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n31YBwCVvhAI",
        "outputId": "4c1bf03c-9d66-48ea-93f2-4489fc20beaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start of iteration 0\n",
            "Current loss value: 13273409000.0\n",
            "Image saved as /content/output/output_at_iteration_0.png\n",
            "Iteration 0 completed in 11s\n",
            "Start of iteration 1\n",
            "Current loss value: 6347451000.0\n",
            "Image saved as /content/output/output_at_iteration_1.png\n",
            "Iteration 1 completed in 4s\n",
            "Start of iteration 2\n",
            "Current loss value: 4452764000.0\n",
            "Image saved as /content/output/output_at_iteration_2.png\n",
            "Iteration 2 completed in 4s\n",
            "Start of iteration 3\n",
            "Current loss value: 3511758300.0\n",
            "Image saved as /content/output/output_at_iteration_3.png\n",
            "Iteration 3 completed in 4s\n",
            "Start of iteration 4\n",
            "Current loss value: 2822316000.0\n",
            "Image saved as /content/output/output_at_iteration_4.png\n",
            "Iteration 4 completed in 4s\n",
            "Start of iteration 5\n",
            "Current loss value: 2412456400.0\n",
            "Image saved as /content/output/output_at_iteration_5.png\n",
            "Iteration 5 completed in 4s\n",
            "Start of iteration 6\n",
            "Current loss value: 2135097300.0\n",
            "Image saved as /content/output/output_at_iteration_6.png\n",
            "Iteration 6 completed in 4s\n",
            "Start of iteration 7\n",
            "Current loss value: 1970264800.0\n",
            "Image saved as /content/output/output_at_iteration_7.png\n",
            "Iteration 7 completed in 4s\n",
            "Start of iteration 8\n",
            "Current loss value: 1860384800.0\n",
            "Image saved as /content/output/output_at_iteration_8.png\n",
            "Iteration 8 completed in 4s\n",
            "Start of iteration 9\n",
            "Current loss value: 1751609500.0\n",
            "Image saved as /content/output/output_at_iteration_9.png\n",
            "Iteration 9 completed in 4s\n",
            "Start of iteration 10\n",
            "Current loss value: 1669193200.0\n",
            "Image saved as /content/output/output_at_iteration_10.png\n",
            "Iteration 10 completed in 4s\n",
            "Start of iteration 11\n",
            "Current loss value: 1578533200.0\n",
            "Image saved as /content/output/output_at_iteration_11.png\n",
            "Iteration 11 completed in 4s\n",
            "Start of iteration 12\n",
            "Current loss value: 1517204700.0\n",
            "Image saved as /content/output/output_at_iteration_12.png\n",
            "Iteration 12 completed in 4s\n",
            "Start of iteration 13\n",
            "Current loss value: 1467499100.0\n",
            "Image saved as /content/output/output_at_iteration_13.png\n",
            "Iteration 13 completed in 4s\n",
            "Start of iteration 14\n",
            "Current loss value: 1425280800.0\n",
            "Image saved as /content/output/output_at_iteration_14.png\n",
            "Iteration 14 completed in 4s\n",
            "Start of iteration 15\n",
            "Current loss value: 1391144700.0\n",
            "Image saved as /content/output/output_at_iteration_15.png\n",
            "Iteration 15 completed in 4s\n",
            "Start of iteration 16\n",
            "Current loss value: 1354899500.0\n",
            "Image saved as /content/output/output_at_iteration_16.png\n",
            "Iteration 16 completed in 4s\n",
            "Start of iteration 17\n",
            "Current loss value: 1326892500.0\n",
            "Image saved as /content/output/output_at_iteration_17.png\n",
            "Iteration 17 completed in 4s\n",
            "Start of iteration 18\n",
            "Current loss value: 1303227000.0\n",
            "Image saved as /content/output/output_at_iteration_18.png\n",
            "Iteration 18 completed in 4s\n",
            "Start of iteration 19\n",
            "Current loss value: 1269311400.0\n",
            "Image saved as /content/output/output_at_iteration_19.png\n",
            "Iteration 19 completed in 4s\n",
            "Start of iteration 20\n",
            "Current loss value: 1246992000.0\n",
            "Image saved as /content/output/output_at_iteration_20.png\n",
            "Iteration 20 completed in 4s\n",
            "Start of iteration 21\n",
            "Current loss value: 1229419000.0\n",
            "Image saved as /content/output/output_at_iteration_21.png\n",
            "Iteration 21 completed in 4s\n",
            "Start of iteration 22\n",
            "Current loss value: 1214691000.0\n",
            "Image saved as /content/output/output_at_iteration_22.png\n",
            "Iteration 22 completed in 4s\n",
            "Start of iteration 23\n",
            "Current loss value: 1202314500.0\n",
            "Image saved as /content/output/output_at_iteration_23.png\n",
            "Iteration 23 completed in 4s\n",
            "Start of iteration 24\n",
            "Current loss value: 1191065700.0\n",
            "Image saved as /content/output/output_at_iteration_24.png\n",
            "Iteration 24 completed in 4s\n",
            "Start of iteration 25\n",
            "Current loss value: 1180488200.0\n",
            "Image saved as /content/output/output_at_iteration_25.png\n",
            "Iteration 25 completed in 4s\n",
            "Start of iteration 26\n",
            "Current loss value: 1170969700.0\n",
            "Image saved as /content/output/output_at_iteration_26.png\n",
            "Iteration 26 completed in 4s\n",
            "Start of iteration 27\n",
            "Current loss value: 1155740700.0\n",
            "Image saved as /content/output/output_at_iteration_27.png\n",
            "Iteration 27 completed in 4s\n",
            "Start of iteration 28\n",
            "Current loss value: 1142597900.0\n",
            "Image saved as /content/output/output_at_iteration_28.png\n",
            "Iteration 28 completed in 4s\n",
            "Start of iteration 29\n",
            "Current loss value: 1132743800.0\n",
            "Image saved as /content/output/output_at_iteration_29.png\n",
            "Iteration 29 completed in 4s\n",
            "Start of iteration 30\n",
            "Current loss value: 1124286000.0\n",
            "Image saved as /content/output/output_at_iteration_30.png\n",
            "Iteration 30 completed in 4s\n",
            "Start of iteration 31\n",
            "Current loss value: 1115296400.0\n",
            "Image saved as /content/output/output_at_iteration_31.png\n",
            "Iteration 31 completed in 4s\n",
            "Start of iteration 32\n",
            "Current loss value: 1107436300.0\n",
            "Image saved as /content/output/output_at_iteration_32.png\n",
            "Iteration 32 completed in 4s\n",
            "Start of iteration 33\n",
            "Current loss value: 1096296700.0\n",
            "Image saved as /content/output/output_at_iteration_33.png\n",
            "Iteration 33 completed in 4s\n",
            "Start of iteration 34\n",
            "Current loss value: 1087182000.0\n",
            "Image saved as /content/output/output_at_iteration_34.png\n",
            "Iteration 34 completed in 4s\n",
            "Start of iteration 35\n",
            "Current loss value: 1075933600.0\n",
            "Image saved as /content/output/output_at_iteration_35.png\n",
            "Iteration 35 completed in 4s\n",
            "Start of iteration 36\n",
            "Current loss value: 1066292300.0\n",
            "Image saved as /content/output/output_at_iteration_36.png\n",
            "Iteration 36 completed in 4s\n",
            "Start of iteration 37\n",
            "Current loss value: 1061817860.0\n",
            "Image saved as /content/output/output_at_iteration_37.png\n",
            "Iteration 37 completed in 4s\n",
            "Start of iteration 38\n",
            "Current loss value: 1057405300.0\n",
            "Image saved as /content/output/output_at_iteration_38.png\n",
            "Iteration 38 completed in 4s\n",
            "Start of iteration 39\n",
            "Current loss value: 1052422700.0\n",
            "Image saved as /content/output/output_at_iteration_39.png\n",
            "Iteration 39 completed in 4s\n",
            "Start of iteration 40\n",
            "Current loss value: 1046551300.0\n",
            "Image saved as /content/output/output_at_iteration_40.png\n",
            "Iteration 40 completed in 4s\n",
            "Start of iteration 41\n",
            "Current loss value: 1040783550.0\n",
            "Image saved as /content/output/output_at_iteration_41.png\n",
            "Iteration 41 completed in 4s\n",
            "Start of iteration 42\n",
            "Current loss value: 1035612400.0\n",
            "Image saved as /content/output/output_at_iteration_42.png\n",
            "Iteration 42 completed in 4s\n",
            "Start of iteration 43\n",
            "Current loss value: 1031173950.0\n",
            "Image saved as /content/output/output_at_iteration_43.png\n",
            "Iteration 43 completed in 4s\n",
            "Start of iteration 44\n",
            "Current loss value: 1026627900.0\n",
            "Image saved as /content/output/output_at_iteration_44.png\n",
            "Iteration 44 completed in 4s\n",
            "Start of iteration 45\n",
            "Current loss value: 1022867460.0\n",
            "Image saved as /content/output/output_at_iteration_45.png\n",
            "Iteration 45 completed in 4s\n",
            "Start of iteration 46\n",
            "Current loss value: 1019472700.0\n",
            "Image saved as /content/output/output_at_iteration_46.png\n",
            "Iteration 46 completed in 4s\n",
            "Start of iteration 47\n",
            "Current loss value: 1016219500.0\n",
            "Image saved as /content/output/output_at_iteration_47.png\n",
            "Iteration 47 completed in 4s\n",
            "Start of iteration 48\n",
            "Current loss value: 1013103740.0\n",
            "Image saved as /content/output/output_at_iteration_48.png\n",
            "Iteration 48 completed in 4s\n",
            "Start of iteration 49\n",
            "Current loss value: 1010084860.0\n",
            "Image saved as /content/output/output_at_iteration_49.png\n",
            "Iteration 49 completed in 4s\n",
            "Start of iteration 50\n",
            "Current loss value: 1007337600.0\n",
            "Image saved as /content/output/output_at_iteration_50.png\n",
            "Iteration 50 completed in 4s\n",
            "Start of iteration 51\n",
            "Current loss value: 1002772200.0\n",
            "Image saved as /content/output/output_at_iteration_51.png\n",
            "Iteration 51 completed in 4s\n",
            "Start of iteration 52\n",
            "Current loss value: 998898300.0\n",
            "Image saved as /content/output/output_at_iteration_52.png\n",
            "Iteration 52 completed in 4s\n",
            "Start of iteration 53\n",
            "Current loss value: 995866700.0\n",
            "Image saved as /content/output/output_at_iteration_53.png\n",
            "Iteration 53 completed in 4s\n",
            "Start of iteration 54\n",
            "Current loss value: 992903700.0\n",
            "Image saved as /content/output/output_at_iteration_54.png\n",
            "Iteration 54 completed in 4s\n",
            "Start of iteration 55\n",
            "Current loss value: 990754560.0\n",
            "Image saved as /content/output/output_at_iteration_55.png\n",
            "Iteration 55 completed in 4s\n",
            "Start of iteration 56\n",
            "Current loss value: 988550800.0\n",
            "Image saved as /content/output/output_at_iteration_56.png\n",
            "Iteration 56 completed in 4s\n",
            "Start of iteration 57\n",
            "Current loss value: 986259300.0\n",
            "Image saved as /content/output/output_at_iteration_57.png\n",
            "Iteration 57 completed in 4s\n",
            "Start of iteration 58\n",
            "Current loss value: 984072260.0\n",
            "Image saved as /content/output/output_at_iteration_58.png\n",
            "Iteration 58 completed in 4s\n",
            "Start of iteration 59\n",
            "Current loss value: 981666300.0\n",
            "Image saved as /content/output/output_at_iteration_59.png\n",
            "Iteration 59 completed in 4s\n",
            "Start of iteration 60\n",
            "Current loss value: 979823800.0\n",
            "Image saved as /content/output/output_at_iteration_60.png\n",
            "Iteration 60 completed in 4s\n",
            "Start of iteration 61\n",
            "Current loss value: 977143550.0\n",
            "Image saved as /content/output/output_at_iteration_61.png\n",
            "Iteration 61 completed in 4s\n",
            "Start of iteration 62\n",
            "Current loss value: 974104960.0\n",
            "Image saved as /content/output/output_at_iteration_62.png\n",
            "Iteration 62 completed in 4s\n",
            "Start of iteration 63\n",
            "Current loss value: 972086300.0\n",
            "Image saved as /content/output/output_at_iteration_63.png\n",
            "Iteration 63 completed in 4s\n",
            "Start of iteration 64\n",
            "Current loss value: 969961500.0\n",
            "Image saved as /content/output/output_at_iteration_64.png\n",
            "Iteration 64 completed in 4s\n",
            "Start of iteration 65\n",
            "Current loss value: 967741700.0\n",
            "Image saved as /content/output/output_at_iteration_65.png\n",
            "Iteration 65 completed in 4s\n",
            "Start of iteration 66\n",
            "Current loss value: 965645060.0\n",
            "Image saved as /content/output/output_at_iteration_66.png\n",
            "Iteration 66 completed in 4s\n",
            "Start of iteration 67\n",
            "Current loss value: 964051200.0\n",
            "Image saved as /content/output/output_at_iteration_67.png\n",
            "Iteration 67 completed in 4s\n",
            "Start of iteration 68\n",
            "Current loss value: 962240260.0\n",
            "Image saved as /content/output/output_at_iteration_68.png\n",
            "Iteration 68 completed in 4s\n",
            "Start of iteration 69\n",
            "Current loss value: 960589800.0\n",
            "Image saved as /content/output/output_at_iteration_69.png\n",
            "Iteration 69 completed in 4s\n",
            "Start of iteration 70\n",
            "Current loss value: 958313340.0\n",
            "Image saved as /content/output/output_at_iteration_70.png\n",
            "Iteration 70 completed in 4s\n",
            "Start of iteration 71\n",
            "Current loss value: 955996600.0\n",
            "Image saved as /content/output/output_at_iteration_71.png\n",
            "Iteration 71 completed in 4s\n",
            "Start of iteration 72\n",
            "Current loss value: 953897340.0\n",
            "Image saved as /content/output/output_at_iteration_72.png\n",
            "Iteration 72 completed in 4s\n",
            "Start of iteration 73\n",
            "Current loss value: 951580000.0\n",
            "Image saved as /content/output/output_at_iteration_73.png\n",
            "Iteration 73 completed in 4s\n",
            "Start of iteration 74\n",
            "Current loss value: 949822340.0\n",
            "Image saved as /content/output/output_at_iteration_74.png\n",
            "Iteration 74 completed in 4s\n",
            "Start of iteration 75\n",
            "Current loss value: 948128900.0\n",
            "Image saved as /content/output/output_at_iteration_75.png\n",
            "Iteration 75 completed in 4s\n",
            "Start of iteration 76\n",
            "Current loss value: 946001900.0\n",
            "Image saved as /content/output/output_at_iteration_76.png\n",
            "Iteration 76 completed in 4s\n",
            "Start of iteration 77\n",
            "Current loss value: 943861900.0\n",
            "Image saved as /content/output/output_at_iteration_77.png\n",
            "Iteration 77 completed in 4s\n",
            "Start of iteration 78\n",
            "Current loss value: 942313340.0\n",
            "Image saved as /content/output/output_at_iteration_78.png\n",
            "Iteration 78 completed in 4s\n",
            "Start of iteration 79\n",
            "Current loss value: 940783360.0\n",
            "Image saved as /content/output/output_at_iteration_79.png\n",
            "Iteration 79 completed in 4s\n",
            "Start of iteration 80\n",
            "Current loss value: 939503300.0\n",
            "Image saved as /content/output/output_at_iteration_80.png\n",
            "Iteration 80 completed in 4s\n",
            "Start of iteration 81\n",
            "Current loss value: 938181500.0\n",
            "Image saved as /content/output/output_at_iteration_81.png\n",
            "Iteration 81 completed in 4s\n",
            "Start of iteration 82\n",
            "Current loss value: 936953340.0\n",
            "Image saved as /content/output/output_at_iteration_82.png\n",
            "Iteration 82 completed in 4s\n",
            "Start of iteration 83\n",
            "Current loss value: 935529150.0\n",
            "Image saved as /content/output/output_at_iteration_83.png\n",
            "Iteration 83 completed in 4s\n",
            "Start of iteration 84\n",
            "Current loss value: 934318460.0\n",
            "Image saved as /content/output/output_at_iteration_84.png\n",
            "Iteration 84 completed in 4s\n",
            "Start of iteration 85\n",
            "Current loss value: 933139400.0\n",
            "Image saved as /content/output/output_at_iteration_85.png\n",
            "Iteration 85 completed in 4s\n",
            "Start of iteration 86\n",
            "Current loss value: 931855000.0\n",
            "Image saved as /content/output/output_at_iteration_86.png\n",
            "Iteration 86 completed in 4s\n",
            "Start of iteration 87\n",
            "Current loss value: 930877440.0\n",
            "Image saved as /content/output/output_at_iteration_87.png\n",
            "Iteration 87 completed in 4s\n",
            "Start of iteration 88\n",
            "Current loss value: 929110600.0\n",
            "Image saved as /content/output/output_at_iteration_88.png\n",
            "Iteration 88 completed in 4s\n",
            "Start of iteration 89\n",
            "Current loss value: 927320400.0\n",
            "Image saved as /content/output/output_at_iteration_89.png\n",
            "Iteration 89 completed in 4s\n",
            "Start of iteration 90\n",
            "Current loss value: 925080770.0\n",
            "Image saved as /content/output/output_at_iteration_90.png\n",
            "Iteration 90 completed in 4s\n",
            "Start of iteration 91\n",
            "Current loss value: 922863360.0\n",
            "Image saved as /content/output/output_at_iteration_91.png\n",
            "Iteration 91 completed in 4s\n",
            "Start of iteration 92\n",
            "Current loss value: 921263500.0\n",
            "Image saved as /content/output/output_at_iteration_92.png\n",
            "Iteration 92 completed in 4s\n",
            "Start of iteration 93\n",
            "Current loss value: 919812350.0\n",
            "Image saved as /content/output/output_at_iteration_93.png\n",
            "Iteration 93 completed in 4s\n",
            "Start of iteration 94\n",
            "Current loss value: 918680450.0\n",
            "Image saved as /content/output/output_at_iteration_94.png\n",
            "Iteration 94 completed in 4s\n",
            "Start of iteration 95\n",
            "Current loss value: 917604540.0\n",
            "Image saved as /content/output/output_at_iteration_95.png\n",
            "Iteration 95 completed in 4s\n",
            "Start of iteration 96\n",
            "Current loss value: 916276500.0\n",
            "Image saved as /content/output/output_at_iteration_96.png\n",
            "Iteration 96 completed in 4s\n",
            "Start of iteration 97\n",
            "Current loss value: 915087500.0\n",
            "Image saved as /content/output/output_at_iteration_97.png\n",
            "Iteration 97 completed in 4s\n",
            "Start of iteration 98\n",
            "Current loss value: 914183300.0\n",
            "Image saved as /content/output/output_at_iteration_98.png\n",
            "Iteration 98 completed in 4s\n",
            "Start of iteration 99\n",
            "Current loss value: 913010800.0\n",
            "Image saved as /content/output/output_at_iteration_99.png\n",
            "Iteration 99 completed in 4s\n"
          ]
        }
      ],
      "source": [
        "evaluator = Evaluator()\n",
        "\n",
        "# run scipy-based optimization (L-BFGS) over the pixels of the generated image\n",
        "# so as to minimize the neural style loss\n",
        "x = preprocess_image(base_image_path)\n",
        "\n",
        "for i in range(iterations):\n",
        "    print('Start of iteration', i)\n",
        "    start_time = time.time()\n",
        "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
        "                                     fprime=evaluator.grads, maxfun=20)\n",
        "    print('Current loss value:', min_val)\n",
        "    # save current generated image\n",
        "    img = deprocess_image(x.copy())\n",
        "    fname = result_prefix / ('output_at_iteration_%d.png' % i)\n",
        "    save_img(fname, img)\n",
        "    end_time = time.time()\n",
        "    print('Image saved as', fname)\n",
        "    print('Iteration %d completed in %ds' % (i, end_time - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkiJtofbWWy1"
      },
      "source": [
        "# 8) Generar imágenes para distintas combinaciones de pesos de las losses. Explicar las diferencias. (Adjuntar las imágenes generadas como archivos separados.)\n",
        "\n",
        "Rta: las nuevas combinaciones aplicadas fueron total_variation_weight = 10, style_weight = 1, content_weight = 0.1. Con estos valores podemos observar que ya que el content_weight es menor en comparación con el style_weight, la imagen generada no se parece mucho a la imagen original. Por otro lado, como el style tampoco es extremadamente alto, la influencia del estilo no es abrumadora. Se adjunta en el mail la carpeta \"8.Variación_de pesos_v2\"\n",
        "\n",
        "Las diferencias detectadas con los pesos originales total_variation_weight = 0.1, style_weight = 10, content_weight = 1, se centran en que en el primer conjunto se puede esperar una imagen donde el estilo domina y hay menos regularidad/coherencia espacial, mientras que en el segundo conjunto de pesos se puede esperar una imagen mas coherente, pero con una presencia mas debil del contenido original y una moderada influencia del estilo. Ver carpeta \"Comparación entre imagenes finales\"\n",
        "\n",
        "# 9) Cambiar las imágenes de contenido y estilo por unas elegidas por usted. Adjuntar el resultado.\n",
        "\n",
        "Respuesta: Se adjunta en el mail Carpeta \"9. Combinación de nuevas imagenes\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Trabajo Final CNN - Style Transfer.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
